# Copy to .env and customize for your machine.

AIRLLM_MODEL_ID=TinyLlama/TinyLlama-1.1B-Chat-v1.0
AIRLLM_MODEL_PATH=
AIRLLM_MODEL_BASE_DIR=
AIRLLM_DEVICE=
AIRLLM_MAX_INPUT_TOKENS=1024
PORT=8000
HF_TOKEN=

# llama-server fallback controls
# Set to 1 to prefer llama-server whenever it is reachable.
AIRLLM_PREFER_LLAMA_SERVER_IF_AVAILABLE=0
# When runtime backend is llama_server, disable extra fallback attempts by default.
AIRLLM_LLAMA_SERVER_DISABLE_FALLBACKS=1
